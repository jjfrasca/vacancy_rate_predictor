{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Training Data Development - Vacancy Rates \n",
    "### Goal:  Create a cleaned development dataset you can use to complete the modeling step of your project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps: \n",
    "● 1. Create dummy or indicator features for categorical variables\n",
    "\n",
    "● 2. Standardize the magnitude of numeric features using a scaler\n",
    "\n",
    "● 3. Split into testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "path= '/Users/josephfrasca/Coding_Stuff/Springboard/Capstone_2/data/interim'\n",
    "os.chdir(path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Vacancy_Rate%</th>\n",
       "      <th>MOE-VacancyRate%</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02333</td>\n",
       "      <td>3.024027</td>\n",
       "      <td>2.199925</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02338</td>\n",
       "      <td>3.116343</td>\n",
       "      <td>2.948791</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02339</td>\n",
       "      <td>4.464646</td>\n",
       "      <td>2.066438</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02341</td>\n",
       "      <td>3.586322</td>\n",
       "      <td>2.340722</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02343</td>\n",
       "      <td>3.732901</td>\n",
       "      <td>2.926524</td>\n",
       "      <td>2011-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264965</th>\n",
       "      <td>NATNL</td>\n",
       "      <td>6.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264966</th>\n",
       "      <td>NATNL</td>\n",
       "      <td>7.175000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264967</th>\n",
       "      <td>NATNL</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264968</th>\n",
       "      <td>NATNL</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264969</th>\n",
       "      <td>NATNL</td>\n",
       "      <td>6.230000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264970 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zipcode  Vacancy_Rate%  MOE-VacancyRate%       Year\n",
       "0        02333       3.024027          2.199925 2011-01-01\n",
       "1        02338       3.116343          2.948791 2011-01-01\n",
       "2        02339       4.464646          2.066438 2011-01-01\n",
       "3        02341       3.586322          2.340722 2011-01-01\n",
       "4        02343       3.732901          2.926524 2011-01-01\n",
       "...        ...            ...               ...        ...\n",
       "264965   NATNL       6.850000          0.000000 2016-01-01\n",
       "264966   NATNL       7.175000          0.000000 2017-01-01\n",
       "264967   NATNL       6.875000          0.000000 2018-01-01\n",
       "264968   NATNL       6.750000          0.000000 2019-01-01\n",
       "264969   NATNL       6.230000          0.000000 2020-01-01\n",
       "\n",
       "[264970 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.read_csv('VacancyRate_Zipcode_AND_National_2011_2020.csv',  dtype={'Zipcode': object}, parse_dates=['Year'])\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zipcode                     object\n",
       "Vacancy_Rate%              float64\n",
       "MOE-VacancyRate%           float64\n",
       "Year                datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Vacancy_Rate%</th>\n",
       "      <th>MOE-VacancyRate%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>02333</td>\n",
       "      <td>3.024027</td>\n",
       "      <td>2.199925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>02338</td>\n",
       "      <td>3.116343</td>\n",
       "      <td>2.948791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>02339</td>\n",
       "      <td>4.464646</td>\n",
       "      <td>2.066438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>02341</td>\n",
       "      <td>3.586322</td>\n",
       "      <td>2.340722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>02343</td>\n",
       "      <td>3.732901</td>\n",
       "      <td>2.926524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Zipcode  Vacancy_Rate%  MOE-VacancyRate%\n",
       "Year                                               \n",
       "2011-01-01   02333       3.024027          2.199925\n",
       "2011-01-01   02338       3.116343          2.948791\n",
       "2011-01-01   02339       4.464646          2.066438\n",
       "2011-01-01   02341       3.586322          2.340722\n",
       "2011-01-01   02343       3.732901          2.926524"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new dataframe, setting the index to 'Year'\n",
    "df = DF.set_index('Year')\n",
    "#Save the DATE labels \n",
    "df_index = df.index\n",
    "#Save the column names\n",
    "df_columns = df.columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zipcode             0\n",
       "Vacancy_Rate%       0\n",
       "MOE-VacancyRate%    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for NaNs\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000000      5.630071\n",
       "100.000000    0.207571\n",
       "20.000000     0.046043\n",
       "33.333333     0.040759\n",
       "25.000000     0.037363\n",
       "                ...   \n",
       "8.671855      0.000377\n",
       "17.389154     0.000377\n",
       "2.754040      0.000377\n",
       "26.238062     0.000377\n",
       "5.466803      0.000377\n",
       "Name: MOE-VacancyRate%, Length: 234862, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique values for each column\n",
    "df['MOE-VacancyRate%'].value_counts()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zipcode               int64\n",
       "Vacancy_Rate%       float64\n",
       "MOE-VacancyRate%    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change National ('NATNL') zipcode to '99999' for later modeling\n",
    "df.Zipcode.replace('NATNL', '99999', inplace=True)\n",
    "df.Zipcode = df.Zipcode.astype('int')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 231848.75 test size: 33121.25\n"
     ]
    }
   ],
   "source": [
    "#check partition sizes with a 8 fold split train/test time series split for all DataFrames\n",
    "print('train size:', len(df) * .875, 'test size:', len(df) * .125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split into testing and training datasets\n",
    "Hint: don’t forget your sklearn functions here, like train_test_split()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate 2020 data from data set for later use and prediction\n",
    "df_2019AND20 = df[df.index > '2018']\n",
    "df = df[df.index < '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define variable X, y\n",
    "X = df.drop('Vacancy_Rate%', axis=1)\n",
    "y = df['Vacancy_Rate%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "tss = TimeSeriesSplit(n_splits = 8)\n",
    "for train_index, test_index in tss.split(X):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index,:]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Baseline Measurement Comparisons\n",
    "Using a Dummy Regressor see what R2, MSE, and MAE would be if the mean of the DataFrames were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.601757567048768\n"
     ]
    }
   ],
   "source": [
    "#initial not even a model\n",
    "train_mean = y_train.mean()\n",
    "\n",
    "print(train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -0.0014593635752446765)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the dummy regressor on the training data\n",
    "dumb_reg = DummyRegressor(strategy='mean')\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "#create dummy regressor predictions \n",
    "y_tr_pred = dumb_reg.predict(X_train)\n",
    "#Make prediction with the single value of the (training) mean.\n",
    "y_te_pred = train_mean * np.ones(len(y_test))\n",
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAEs: 11.649025685891326 12.356698194671722\n",
      "MSEs: 266.9221614513521 296.48278858832686\n"
     ]
    }
   ],
   "source": [
    "#establish baseline for mean absolute error and mean square error \n",
    "print('MAEs:', mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred))\n",
    "print('MSEs:', mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Create dummy or indicator features for categorical variables\n",
    "Hint: you’ll need to think about your old favorite pandas functions here like\n",
    "get_dummies() . Consult this guide for help.\n",
    "<https://towardsdatascience.com/the-dummys-guide-to-creating-dummy-variables-f21faddb1d40>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step not needed as the zipcode variable was changed to integer above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Standardize the magnitude of numeric features using a scaler\n",
    "Hint: you might need to employ Python code like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscaler = StandardScaler()\\n#fit the scaler on the training set\\nscaler.fit(X_train)\\n#apply the scaling to both the train and test split\\nX_tr_scaled = scaler.transform(X_train)\\nX_te_scaled = scaler.transform(X_test)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#don't need because everythin is % (0-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Model: Train the model on the train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions using the model on both train and test splits\n",
    "y_tr_pred = lm.predict(X_train)\n",
    "y_te_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: (0.4826938195558145, 0.4819883171151147)\n"
     ]
    }
   ],
   "source": [
    "#Assess model performance\n",
    "# r^2 - train, test\n",
    "r2 = r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)\n",
    "print('r2:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is markedly better performance than when using Dummy variable/mean for R^2 (see earlier):**\n",
    "\n",
    "Dummy R2 = (0.0, -0.0014593635752446765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: (7.940877958949165, 8.326015280389571)\n"
     ]
    }
   ],
   "source": [
    "#MAE - train, test\n",
    "mae = mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)\n",
    "print('mae:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: (138.0804838163052, 153.35774355811242)\n"
     ]
    }
   ],
   "source": [
    "# MSE - train, test\n",
    "mse = mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)\n",
    "print('mse:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is markedly better performance than when using Dummy variable/mean for R^2 (see earlier):**\n",
    "\n",
    "Dummy -\n",
    "\n",
    "MAEs: 11.649025685891326 12.356698194671722\n",
    "\n",
    "MSEs: 266.9221614513521 296.48278858832686\n",
    "\n",
    "**MSE still very high (possibly due to this being a large data set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save vacancy rate data for modeling - remember to use random state=42!\n",
    "df.to_csv(r'/Users/josephfrasca/Coding_Stuff/Springboard/Capstone_2/data/processed/VacancyRate_Zipcode_AND_National_2011_2018', index=False)\n",
    "df_2019AND20.to_csv(r'/Users/josephfrasca/Coding_Stuff/Springboard/Capstone_2/data/processed/VacancyRate_Zipcode_National_2019_2020', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the scaled training and test splits\n",
    "\n",
    "#X_tr_scaled.to_csv(r'/Users/josephfrasca/Coding_Stuff/Springboard/Capstone_2/data/processed/X_tr_scaled', index=False)\n",
    "#X_te_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This summary should provide a quick overview for someone wanting to know quickly why the given model was chosen for the next part of the business problem to help guide important business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loaded data and made 'Year' column as datetime index to prepare for time series analysis\n",
    "- inspected data for NaNs and unique values\n",
    "- separated data from years 2014-2018 and 2019-2020 data for later use and prediction\n",
    "- performed TimeSeries train test split \n",
    "- estabilshed baseline comparisons using dummy regressors\n",
    "- trained a linear regression model on the training data\n",
    "        - this yielded an R2 of .48 on test set\n",
    "        - MAE of 8.33 on test set\n",
    "        - MSE of 153.36 on test set\n",
    "        - markedly better performance than when using Dummy variable/mean \n",
    "        - model underpeforms the other multiple regression models, ie. linear regression, ridge regression, random forest models in notebook 4.3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
